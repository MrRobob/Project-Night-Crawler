import requests
from bs4 import BeautifulSoup
from requests.exceptions import RequestException


def crawl_stepstone(keywords, location, radius):
    """
    Durchsucht StepStone nach Jobs anhand von Keywords, Standort und Radius.
    Gibt eine Liste mit Jobdaten zur√ºck.
    """

    # Keywords & Location formatieren
    formatted_keywords_a = "-".join(keywords)
    formatted_location = location.lower().replace(" ", "-")

    # Grund-URL mit Platzhaltern f√ºr Radius
    url = (
        f"https://www.stepstone.de/jobs/{formatted_keywords_a}/"
        f"in-{formatted_location}?radius={radius}&sort=2&action=sort_publish"
    )

    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/91.0.4472.124 Safari/537.36"
        )
    }

    new_jobs = []

    # Durchsuche Seiten 1 bis 6
    for page in range(1, 7):
        search_url = f"{url}&page={page}"
        print(f"üîç Suche auf: {search_url}")

        try:
            response = requests.get(search_url, headers=headers, timeout=30)
            response.raise_for_status()
            print("Status Code:", response.status_code)
            print(response.text[:500])  # Nur ein Ausschnitt zur Pr√ºfung

            if response.status_code == 200:
                soup = BeautifulSoup(response.content, "html.parser")
                job_cards = soup.find_all(
                    "article", attrs={"data-testid": "job-item"}
                )

                for job in job_cards:
                    title_element = job.find("a", href=True)
                    title = (
                        title_element.get_text(strip=True)
                        if title_element else "Kein Titel"
                    )
                    link = (
                        "https://www.stepstone.de" + title_element["href"]
                        if title_element else "Kein Link"
                    )

                    company = job.find(
                        "span", attrs={"data-testid": "job-item-company-name"}
                    )
                    company_text = (
                        company.get_text(strip=True)
                        if company else "Keine Firma"
                    )

                    job_data = {
                        "title": title,
                        "company": company_text,
                        "link": link,
                        "source": "StepStone",
                    }

                    new_jobs.append(job_data)

        except RequestException as e:
            print(f"‚ùå Fehler bei der Anfrage an Seite {page}: {e}")

    return new_jobs


if __name__ == "__main__":
    result = crawl_stepstone(["javascript", "entwickler"], "berlin", 30)
    for job in result:
        print(job)
